{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3aab7f6-861b-4844-92d9-9705e4d04c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test time augument\n",
    "#ensemble\n",
    "#treshold\n",
    "import timm\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import torchvision\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import EmbryoDataset\n",
    "from models import CustomVit\n",
    "from augmentations import Cutout\n",
    "from utils import SAM,LR_Scheduler\n",
    "from utils import RandAugment,PadAndResize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526d4aab-fb6f-4a31-a804-75300bf904d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b252b-621d-44d7-a685-368b0f881270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_size = 224\n",
    "rho = 0.05\n",
    "cuda_device_index = 0\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "warmup_epochs = 3\n",
    "weight_decay = 0.005\n",
    "epochs = 100\n",
    "num_workers = 8 # workers for dataloader\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "root = \"/data/train\"\n",
    "\n",
    "train_file_0=\"train_data_fold_3_0.pkl\"\n",
    "validation_file_0=\"validation_data_fold_3_0.pkl\"\n",
    "train_file_1=\"train_data_fold_3_1.pkl\"\n",
    "validation_file_1=\"validation_data_fold_3_1.pkl\"\n",
    "\n",
    "n = 5 # for randaugment\n",
    "m = 12 # for randaugment\n",
    "checkpoint_dir = \"Models/ensemble_fold_3\"\n",
    "if os.path.isdir(checkpoint_dir) == False:\n",
    "    os.makedirs(checkpoint_dir)\n",
    "device = torch.device(\"cuda:\" + str(cuda_device_index) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = timm.create_model(\"hf_hub:timm/maxvit_small_tf_224.in1k\", pretrained=True,num_classes=2)\n",
    "labels=[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa5ad0-e725-43bc-b8f2-b19e6ef64457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms_train = torchvision.transforms.Compose([\n",
    "    PadAndResize((img_size,img_size)), \n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.3),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.3),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "transforms_train.transforms.insert(0, RandAugment(n, m))\n",
    "transforms_train.transforms.append(Cutout(n_holes=5, length=32, p=0.3))\n",
    "\n",
    "transforms_validation = torchvision.transforms.Compose([\n",
    "    PadAndResize((img_size,img_size)), \n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "with open(train_file_0, 'rb') as file:\n",
    "    train_data_0 = pickle.load(file)\n",
    "    \n",
    "with open(validation_file_0, 'rb') as file:\n",
    "    validation_data_0 = pickle.load(file)\n",
    "    \n",
    "with open(train_file_1, 'rb') as file:\n",
    "    train_data_1 = pickle.load(file)\n",
    "    \n",
    "with open(validation_file_1, 'rb') as file:\n",
    "    validation_data_1 = pickle.load(file)\n",
    "    \n",
    "\n",
    "    \n",
    "dataset_train_0 = EmbryoDataset(root=root, \n",
    "                         fold_splitter=train_data_0,\n",
    "                         transforms=transforms_train)\n",
    "dataset_validation_0 = EmbryoDataset(root=root, \n",
    "                         fold_splitter=validation_data_0,\n",
    "                         transforms=transforms_validation)\n",
    "\n",
    "dataset_train_1 = EmbryoDataset(root=root, \n",
    "                         fold_splitter=train_data_1,\n",
    "                         transforms=transforms_train)\n",
    "\n",
    "dataset_validation_1 = EmbryoDataset(root=root, \n",
    "                         fold_splitter=validation_data_1,\n",
    "                         transforms=transforms_validation)\n",
    "\n",
    "print(len(dataset_validation_0))\n",
    "print(len(dataset_validation_1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5425e372-5f6b-43d0-be76-882877fb77c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader_train_0 = DataLoader(dataset_train_0, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                             drop_last=True)\n",
    "dataloader_valid_0 = DataLoader(dataset_validation_0, batch_size=1, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380c208b-aeee-432f-a2f8-8daffbb834e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader_train_1 = DataLoader(dataset_train_1, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                             drop_last=True)\n",
    "dataloader_valid_1 = DataLoader(dataset_validation_1, batch_size=1, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f12e8a9-4ab6-4079-9f99-343f4404b49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_log(file, text = \"\", timp=True):\n",
    "    string = \"\"\n",
    "    if timp:\n",
    "        timestamp = time()\n",
    "        dt_object = datetime.fromtimestamp(timestamp)\n",
    "        string += str(dt_object) + \": \"\n",
    "    string += text + \"\\n\"\n",
    "    \n",
    "    f = open(file, \"a\")\n",
    "    f.write(string)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423480b9-43a9-4a4c-a9ec-7caf0f9bc91b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_to_log(epoch, train_loss, valid_dice, valid_f1,n,n1,n2, start_time):\n",
    "    file_log = checkpoint_dir+\"/train_log.txt\"\n",
    "    print_log(file_log)\n",
    "    print_log(file_log, \"epoch: {}\".format(epoch), False)\n",
    "    print_log(file_log, \"train loss: {}\". format(train_loss))\n",
    "    print_log(file_log, \"valid metric: {}\". format(valid_dice))\n",
    "    print_log(file_log, \"valid F1 score: {}\". format(valid_f1))\n",
    "    print_log(file_log, \"Total correct: {}\". format(n))\n",
    "    print_log(file_log, \"Total correct F: {}\". format(n1))\n",
    "    print_log(file_log, \"Total correct T: {}\". format(n2))\n",
    "    # print_log(file_log, \"test metric: {}\". format(test_dice))\n",
    "    \n",
    "    end_time = time()\n",
    "    print_log(file_log, \"This epoch took {} s\".format(\"{:.4f}\".format(end_time-start_time)))\n",
    "    print_log(file_log, \"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148779ff-2a86-44fc-870d-a09e7458cb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_plot(arr, name, time):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(time + ' ' + name)\n",
    "    plt.plot(arr,label=time)\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(name)\n",
    "    plt.legend()\n",
    "    plt.savefig(checkpoint_dir+\"/Classification \" + time + ' ' + name + '.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "015518e9-2788-4273-b4a7-02bc89fc2fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                              | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "base_optimizer = optim.SGD\n",
    "optimizer=SAM(model.parameters(), \n",
    "                base_optimizer, rho=rho, lr=learning_rate, momentum=momentum, \n",
    "                weight_decay=weight_decay)\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(),\n",
    "#                                lr=learning_rate, weight_decay=weight_decay)\n",
    "epochs = 1000\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "var = tqdm(range(epochs))\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1996d3-563b-4daa-b22f-3441b3d99871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_interval = 1\n",
    "val_interval_test = 5\n",
    "\n",
    "best_metric_0 = -1\n",
    "best_metric_f1_0 = -1\n",
    "best_metric_epoch_0 = -1\n",
    "best_metric_f1_epoch_0 = -1\n",
    "\n",
    "best_metric_1 = -1\n",
    "best_metric_f1_1 = -1\n",
    "best_metric_epoch_1 = -1\n",
    "best_metric_f1_epoch_1 = -1\n",
    "\n",
    "epoch_loss_values = []\n",
    "metric_values_0 = []\n",
    "metric_values_f1_0 = []\n",
    "metric_values_1 = []\n",
    "metric_values_f1_1 = []\n",
    "epochs = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba57cdd3-6575-4612-9a54-b033f91ad83b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for x in dataloader_train:\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72777eaa-3915-4417-a1d0-1a3e538b4d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in var:\n",
    "    model.train()\n",
    "    epoch_loss=0\n",
    "    step=0\n",
    "    start_time=time()\n",
    "    for inputs_1,labels_1 in dataloader_train_1:\n",
    "        #optimizer.zero_grad()\n",
    "        inputs_0,labels_0 = next(iter(dataloader_train_0))\n",
    "        inputs=torch.cat((inputs_0,inputs_1))\n",
    "        labels=torch.cat((labels_0,labels_1))\n",
    "        #print(days.shape)\n",
    "        order=torch.randperm(batch_size*2)\n",
    "        inputs=inputs[order][:][:]\n",
    "        labels=labels[order][:][:]\n",
    "        step+=1\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.first_step(zero_grad=True)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(dataset_train_1) // dataloader_train_1.batch_size\n",
    "        var.set_description(f\"{step}/{epoch_len}, train_loss: {loss.item()}\")\n",
    "        \n",
    "        outputs2 = model(inputs)\n",
    "        loss = loss_function(outputs2, labels)\n",
    "        loss.backward()\n",
    "        optimizer.second_step(zero_grad=True)\n",
    "    scheduler.step()\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    var.set_description(\"epoch {} average loss: {}\".format(epoch + 1, epoch_loss))\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            num_correct_0 = 0.0\n",
    "            num_correct_1 = 0.0\n",
    "            num_correct=0.0\n",
    "            metric_count = 0\n",
    "            f1_output = []\n",
    "            f1_labels = []\n",
    "            for val_images, val_labels in dataloader_valid_0:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                with torch.no_grad():\n",
    "                    val_outputs = model(val_images)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                    metric_count += len(value)\n",
    "                    num_correct_0 += value.sum().item()\n",
    "                    f1_output.append(val_outputs.argmax(dim=1).cpu().item())\n",
    "                    f1_labels.append(val_labels.cpu().item())\n",
    "            for val_images, val_labels in dataloader_valid_1:\n",
    "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "                with torch.no_grad():\n",
    "                    val_outputs = model(val_images)\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n",
    "                    metric_count += len(value)\n",
    "                    num_correct_1 += value.sum().item()\n",
    "                    f1_output.append(val_outputs.argmax(dim=1).cpu().item())\n",
    "                    f1_labels.append(val_labels.cpu().item())\n",
    "            \n",
    "            num_correct=num_correct_0+num_correct_1\n",
    "            metric = num_correct / metric_count\n",
    "            metric_values_0.append(metric)\n",
    "            f1 = f1_score(f1_labels, f1_output, average='macro')\n",
    "            metric_values_f1_0.append(f1)\n",
    "            print(f\"Images correct:  {int(num_correct)}: T:{int(num_correct_1)}, F:{int(num_correct_0)} \")\n",
    "            if metric > best_metric_0:\n",
    "                best_metric_0 = metric\n",
    "                best_metric_epoch_0 = epoch + 1\n",
    "                torch.save(model.state_dict(), checkpoint_dir+\"/model_best_0.pth\")\n",
    "\n",
    "            if f1 > best_metric_f1_0:\n",
    "                best_metric_f1_0 = f1\n",
    "                best_metric_f1_epoch_0 = epoch + 1\n",
    "                torch.save(model.state_dict(), checkpoint_dir+\"/model_best_f1_0.pth\")\n",
    "                \n",
    "      \n",
    "            print_to_log(epoch, epoch_loss_values[-1], metric_values_0[-1], metric_values_f1_0[-1],num_correct,num_correct_0,num_correct_1, start_time)\n",
    "\n",
    "            make_plot(epoch_loss_values, \"Lossss\", \"train\")\n",
    "            make_plot(metric_values_0, \"Metric_0\", \"valid\")\n",
    "            make_plot(metric_values_f1_0, \"F1 score_0\", \"valid\")\n",
    "        # make_plot(epoch_loss_values, metric_values)\n",
    "\n",
    "    if (epoch+1) % 25 == 0:\n",
    "        torch.save(model.state_dict(), checkpoint_dir+\"/last_metric_model.pth\")\n",
    "\n",
    "print_log(checkpoint_dir+\"/train_log.txt\", f\"Training completed, best_metric: {best_metric} at epoch: {best_metric_epoch}\", False)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
